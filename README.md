**Facial Expression detection using Compact Convolutional Transformer(CCT)**

**Project Overview**

This project involves building a facial expression detection system using machine learning. The model leverages the Compact Convolutional Transformer (CCT) architecture, which combines convolutional layers and transformers for effective facial expression classification. The model is trained on the FER-2013 dataset, which contains facial images labeled with various emotions such as happy, sad, angry, etc.

**Table of contents**

## **Table of Contents**

- [Project Description](#project-description)
- [Technologies Used](#technologies-used)
- [Dataset](#dataset)
- [Process](#process)
- [Model Training](#model-training)
- [Results](#results)

**Project Description**

Facial expression detection is a key application in human-computer interaction. This project uses the Compact Convolutional Transformer (CCT) model, which is known for its ability to capture both local and global features of images effectively. By combining CNNs and transformers, the model achieves high accuracy in classifying facial emotions from images.

The goal of this project is to develop a system that can predict facial expressions in real-time or from static images, with applications in fields like customer service, healthcare, and entertainment.

**Technologies Used**

1. **Programming Language**: Python
2. **Libraries**: 
   1. TensorFlow/Keras for model development and training
   2. OpenCV for image preprocessing and video capture
   3. NumPy for numerical operations and data manipulation
   4. Matplotlib for visualizing results and training performance

3. **Model**: Compact Convolutional Transformer (CCT)
4. **Dataset**: We have collected the database from kaggle. This project uses the FER-2013 dataset, which contains over 35,000 labeled images representing 7 different emotions (angry, disgusted, fearful, happy, sad, surprised, and neutral).


